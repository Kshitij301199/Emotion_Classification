{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Reader(Dataset):\n",
    "    def __init__(self, X:pd.Series, Y:pd.Series, tokenizer, max_len:int = 184) -> None:\n",
    "        super().__init__()\n",
    "        self.texts = X['text'].to_list()\n",
    "        self.labels = Y['label'].to_list()\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index) -> list:\n",
    "        \n",
    "        encoding = self.tokenizer(self.texts[index], return_tensors='pt',\n",
    "                                     padding='max_length',max_length = self.max_len,\n",
    "                                    truncation=True, add_special_tokens=True)\n",
    "        return [\n",
    "            torch.tensor(self.labels[index]).long(),\n",
    "            {'input_ids':encoding['input_ids'],\n",
    "             'attention_mask':encoding['attention_mask']\n",
    "            }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/train/X.csv\")[:100]\n",
    "Y_train = pd.read_csv(\"../data/train/Y.csv\")[:100]\n",
    "\n",
    "X_val = pd.read_csv(\"../data/val/X.csv\")[:20]\n",
    "Y_val = pd.read_csv(\"../data/val/Y.csv\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data_Reader(X_train,Y_train,tokenizer,max_len=136)\n",
    "val_data = Data_Reader(X_val,Y_val,tokenizer,max_len=136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batched = DataLoader(train_data, batch_size=8, shuffle=True, drop_last= True)\n",
    "val_data_batched = DataLoader(val_data, batch_size=8, shuffle=True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:00<00:00, 33.33it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_count = 0\n",
    "for batch in tqdm(train_data_batched):\n",
    "    if batch_count == 0:\n",
    "        labels = batch[0]\n",
    "        inputs = batch[1]\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.squeeze(1)\n",
    "        batch_count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BiLSTM(nn.Module):\n",
    "#     def __init__(self,hidden_size:int = 256, num_layers:int = 1) -> None:\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.bert = BertModel.from_pretrained('bert-base-uncased',output_hidden_states= True)\n",
    "#         self.drop_bert = nn.Dropout(0.1)\n",
    "#         self.bilstm = nn.LSTM(input_size=768, hidden_size= hidden_size, num_layers= num_layers, bidirectional= True, batch_first= True)\n",
    "#         self.dense = nn.Sequential(nn.Linear(in_features= hidden_size*2, out_features= 32),\n",
    "#                                     nn.ReLU(),\n",
    "#                                     nn.Linear(in_features= 32, out_features= 6),\n",
    "#                                     nn.Softmax(dim=1))\n",
    "        \n",
    "#         # self.apply(init_weights)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.bert(**x).hidden_states[-2]\n",
    "#         out = self.drop_bert(out)\n",
    "#         lstm_out, _ = self.bilstm(out, None)\n",
    "#         lstm_out = lstm_out[:,-1,:]\n",
    "#         # for i in range(out.size(-2)):\n",
    "#         #     if i == 0:\n",
    "#         #         l_out, (hidden,cell) = self.bilstm(out[:,i,:].unsqueeze(1))\n",
    "#         #     else:\n",
    "#         #         l_out, (hidden,cell) = self.bilstm(out[:,i,:].unsqueeze(1),(hidden,cell))\n",
    "        \n",
    "#         # l_out = l_out.squeeze(1)\n",
    "#         final_output = self.dense(lstm_out)\n",
    "#         return final_output\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes= 6):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "        # self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.bert(**x)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_accuracy(dataloader, model):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    for batch in dataloader:\n",
    "        labels = batch[0]\n",
    "        inputs = batch[1]\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.squeeze(1)\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "\n",
    "        hits = sum(preds == labels)\n",
    "        acc += hits/labels.size(0)\n",
    "    avg_acc = acc/len(dataloader)\n",
    "    \n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertclassifier = BERTClassifier()\n",
    "# bilstm = BiLSTM(hidden_size= 128)\n",
    "model_opt = torch.optim.Adam(params= bertclassifier.parameters(), lr= 5e-5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:13<02:23, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 \t Loss: 1.77956 \t Val Acc: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:25<02:09, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2 \t Loss: 1.78419 \t Val Acc: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:38<01:54, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3 \t Loss: 1.77663 \t Val Acc: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:51<01:44, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4 \t Loss: 1.79105 \t Val Acc: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [01:04<01:30, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5 \t Loss: 1.78146 \t Val Acc: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [01:16<01:16, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6 \t Loss: 1.77576 \t Val Acc: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [01:29<01:03, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7 \t Loss: 1.78911 \t Val Acc: 43.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [01:42<00:50, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8 \t Loss: 1.77904 \t Val Acc: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [01:55<00:38, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9 \t Loss: 1.77107 \t Val Acc: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [02:07<00:25, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10 \t Loss: 1.78275 \t Val Acc: 43.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [02:20<00:12, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11 \t Loss: 1.78402 \t Val Acc: 31.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [02:33<00:00, 12.83s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12 \t Loss: 1.76979 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:18<03:27, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 13 \t Loss: 1.76547 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:31<02:34, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14 \t Loss: 1.75351 \t Val Acc: 12.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:44<02:08, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15 \t Loss: 1.78575 \t Val Acc: 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:57<01:48, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16 \t Loss: 1.76209 \t Val Acc: 12.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [01:09<01:32, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17 \t Loss: 1.74953 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [01:26<01:26, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 18 \t Loss: 1.75202 \t Val Acc: 12.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [01:40<01:10, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19 \t Loss: 1.75216 \t Val Acc: 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [01:52<00:54, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20 \t Loss: 1.74998 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [02:05<00:40, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 21 \t Loss: 1.77061 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [02:19<00:27, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22 \t Loss: 1.80556 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [02:31<00:13, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23 \t Loss: 1.77968 \t Val Acc: 12.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [02:44<00:00, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24 \t Loss: 1.76044 \t Val Acc: 18.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_loss, batch_count = [], 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    # val_acc = validate_accuracy(val_data_batched, bertclassifier).item()\n",
    "    # print(f\"Epoch: {epoch}, Val Acc: {val_acc*100:.2f}%\")\n",
    "    for batch in tqdm(train_data_batched):\n",
    "        bilstm.train()\n",
    "        batch_count += 1\n",
    "        labels = batch[0]\n",
    "        inputs = batch[1]\n",
    "        for key, value in inputs.items():\n",
    "            inputs[key] = value.squeeze(1)\n",
    "        \n",
    "        output = bilstm(inputs)\n",
    "        loss = loss_function(output,labels)\n",
    "        \n",
    "        model_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(bilstm.parameters(), 2)\n",
    "        model_opt.step()\n",
    "        \n",
    "        val_acc = validate_accuracy(val_data_batched, bilstm).item()\n",
    "        \n",
    "        print(f\"Batch: {batch_count} \\t Loss: {loss.item():.5f} \\t Val Acc: {val_acc*100:.2f}%\")\n",
    "        batch_loss.append(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Save PyTorch model parameters to a file.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): PyTorch model to save.\n",
    "    - filepath (str): Filepath to save the model parameters.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model parameters saved to '{filepath}'\")\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Load PyTorch model parameters from a file.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): PyTorch model to load parameters into.\n",
    "    - filepath (str): Filepath to the saved model parameters.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    print(f\"Model parameters loaded from '{filepath}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to 'bert_model.pth'\n"
     ]
    }
   ],
   "source": [
    "save_model(bertclassifier, \"bert_model2.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
