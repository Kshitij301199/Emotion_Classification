{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0      i just feel really helpless and heavy hearted      4\n",
       "1  ive enjoyed being able to slouch about relax a...      0\n",
       "2  i gave up my internship with the dmrg and am f...      4\n",
       "3                         i dont know i feel so lost      0\n",
       "4  i am a kindergarten teacher and i am thoroughl...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/text.csv\").drop(columns=\"Unnamed: 0\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416809 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416809 non-null  object\n",
      " 1   label   416809 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence: str) -> list:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens: list) -> str:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens_wo_stop_words = [token for token in tokens if token not in stop_words]\n",
    "    # out = \" \".join(tokens_wo_stop_words)\n",
    "    return tokens_wo_stop_words\n",
    "\n",
    "def lemmatize(tokens: list) -> list:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_words\n",
    "\n",
    "def stemming(tokens: list) -> list:\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['text'].apply(tokenize)\n",
    "data['tokens_stemm'] = data['tokens'].apply(stemming).apply(remove_stopwords)\n",
    "data['tokens_lemma'] = data['tokens'].apply(lemmatize).apply(remove_stopwords)\n",
    "# data['tokens_stemm'] = data['tokens_stemm'].apply(tokenize)\n",
    "# data['tokens_lemma'] = data['tokens_lemma'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemm</th>\n",
       "      <th>tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, just, feel, really, helpless, and, heavy, ...</td>\n",
       "      <td>[feel, realli, helpless, heavi, heart]</td>\n",
       "      <td>[feel, really, helpless, heavy, hearted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ive, enjoyed, being, able, to, slouch, about,...</td>\n",
       "      <td>[ive, enjoy, abl, slouch, relax, unwind, frank...</td>\n",
       "      <td>[ive, enjoyed, able, slouch, relax, unwind, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, gave, up, my, internship, with, the, dmrg,...</td>\n",
       "      <td>[gave, internship, dmrg, feel, distraught]</td>\n",
       "      <td>[gave, internship, dmrg, feeling, distraught]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, dont, know, i, feel, so, lost]</td>\n",
       "      <td>[dont, know, feel, lost]</td>\n",
       "      <td>[dont, know, feel, lost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, am, a, kindergarten, teacher, and, i, am, ...</td>\n",
       "      <td>[kindergarten, teacher, thoroughli, weari, job...</td>\n",
       "      <td>[kindergarten, teacher, thoroughly, weary, job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i was beginning to feel quite disheartened</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, was, beginning, to, feel, quite, dishearte...</td>\n",
       "      <td>[wa, begin, feel, quit, dishearten]</td>\n",
       "      <td>[wa, beginning, feel, quite, disheartened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i would think that whomever would be lucky eno...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, would, think, that, whomever, would, be, l...</td>\n",
       "      <td>[would, think, whomev, would, lucki, enough, s...</td>\n",
       "      <td>[would, think, whomever, would, lucky, enough,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i fear that they won t ever feel that deliciou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, fear, that, they, won, t, ever, feel, that...</td>\n",
       "      <td>[fear, ever, feel, delici, excit, christma, ev...</td>\n",
       "      <td>[fear, ever, feel, delicious, excitement, chri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>im forever taking some time out to have a lie ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[im, forever, taking, some, time, out, to, hav...</td>\n",
       "      <td>[im, forev, take, time, lie, becaus, feel, weird]</td>\n",
       "      <td>[im, forever, taking, time, lie, feel, weird]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i can still lose the weight without feeling de...</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, can, still, lose, the, weight, without, fe...</td>\n",
       "      <td>[still, lose, weight, without, feel, depriv]</td>\n",
       "      <td>[still, lose, weight, without, feeling, deprived]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0      i just feel really helpless and heavy hearted      4   \n",
       "1  ive enjoyed being able to slouch about relax a...      0   \n",
       "2  i gave up my internship with the dmrg and am f...      4   \n",
       "3                         i dont know i feel so lost      0   \n",
       "4  i am a kindergarten teacher and i am thoroughl...      4   \n",
       "5         i was beginning to feel quite disheartened      0   \n",
       "6  i would think that whomever would be lucky eno...      2   \n",
       "7  i fear that they won t ever feel that deliciou...      1   \n",
       "8  im forever taking some time out to have a lie ...      5   \n",
       "9  i can still lose the weight without feeling de...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, just, feel, really, helpless, and, heavy, ...   \n",
       "1  [ive, enjoyed, being, able, to, slouch, about,...   \n",
       "2  [i, gave, up, my, internship, with, the, dmrg,...   \n",
       "3                 [i, dont, know, i, feel, so, lost]   \n",
       "4  [i, am, a, kindergarten, teacher, and, i, am, ...   \n",
       "5  [i, was, beginning, to, feel, quite, dishearte...   \n",
       "6  [i, would, think, that, whomever, would, be, l...   \n",
       "7  [i, fear, that, they, won, t, ever, feel, that...   \n",
       "8  [im, forever, taking, some, time, out, to, hav...   \n",
       "9  [i, can, still, lose, the, weight, without, fe...   \n",
       "\n",
       "                                        tokens_stemm  \\\n",
       "0             [feel, realli, helpless, heavi, heart]   \n",
       "1  [ive, enjoy, abl, slouch, relax, unwind, frank...   \n",
       "2         [gave, internship, dmrg, feel, distraught]   \n",
       "3                           [dont, know, feel, lost]   \n",
       "4  [kindergarten, teacher, thoroughli, weari, job...   \n",
       "5                [wa, begin, feel, quit, dishearten]   \n",
       "6  [would, think, whomev, would, lucki, enough, s...   \n",
       "7  [fear, ever, feel, delici, excit, christma, ev...   \n",
       "8  [im, forev, take, time, lie, becaus, feel, weird]   \n",
       "9       [still, lose, weight, without, feel, depriv]   \n",
       "\n",
       "                                        tokens_lemma  \n",
       "0           [feel, really, helpless, heavy, hearted]  \n",
       "1  [ive, enjoyed, able, slouch, relax, unwind, fr...  \n",
       "2      [gave, internship, dmrg, feeling, distraught]  \n",
       "3                           [dont, know, feel, lost]  \n",
       "4  [kindergarten, teacher, thoroughly, weary, job...  \n",
       "5         [wa, beginning, feel, quite, disheartened]  \n",
       "6  [would, think, whomever, would, lucky, enough,...  \n",
       "7  [fear, ever, feel, delicious, excitement, chri...  \n",
       "8      [im, forever, taking, time, lie, feel, weird]  \n",
       "9  [still, lose, weight, without, feeling, deprived]  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data['tokens_stemm'].apply(len) == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_w_stem_lemm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(column: pd.Series):\n",
    "    max_len = 0\n",
    "    for index, item in column.items():\n",
    "        length = len(item)\n",
    "        if length > max_len:\n",
    "            max_len = length\n",
    "    return max_len\n",
    "\n",
    "def get_unique_words(column: pd.Series):\n",
    "    unique_words = set()\n",
    "    for index, item in column.items():\n",
    "        [unique_words.add(word) for word in item if word not in unique_words]\n",
    "        \n",
    "    return len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "80\n",
      "51797\n",
      "67592\n"
     ]
    }
   ],
   "source": [
    "print(get_max_len(data['tokens_stemm']))\n",
    "print(get_max_len(data['tokens_lemma']))\n",
    "print(get_unique_words(data['tokens_stemm']))\n",
    "print(get_unique_words(data['tokens_lemma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416113"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['tokens_stemm'], data['label'], test_size=0.2, random_state=42)\n",
    "# 0.125 x 0.8 = 0.1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat((X_train,y_train), axis=1).reset_index()\n",
    "val_data = pd.concat((X_val,y_val), axis=1).reset_index()\n",
    "test_data = pd.concat((X_test,y_test), axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=52000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['<OOV>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequence: list, max_len:int = 100):\n",
    "    seq = tokenizer.texts_to_sequences(sequence)\n",
    "    seq = [sub_seq if sub_seq != [] else [1] for sub_seq in seq]\n",
    "    try:\n",
    "        seq_ten = torch.tensor(seq).flatten()\n",
    "        out_ten = torch.zeros(size= (max_len,)).long()\n",
    "        out_ten[:seq_ten.size(0)] = seq_ten\n",
    "        return out_ten\n",
    "    except ValueError:\n",
    "        print(seq)\n",
    "        return torch.zeros(size= (max_len,)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens_stemm</th>\n",
       "      <th>label</th>\n",
       "      <th>padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216356</td>\n",
       "      <td>[im, feel, virtuou, avoid, chip, aisl, altogeth]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(4), tensor(2), tensor(699), tensor(849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69696</td>\n",
       "      <td>[im, quit, certain, im, tough, time, battl, th...</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(4), tensor(74), tensor(600), tensor(4)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196326</td>\n",
       "      <td>[wasnt, feel, quit, thi, appreci, howev, shove...</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(249), tensor(2), tensor(74), tensor(6)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207657</td>\n",
       "      <td>[feel, disgust]</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(2), tensor(376), tensor(0), tensor(0),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31333</td>\n",
       "      <td>[feel, fuck, dumb]</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(2), tensor(226), tensor(528), tensor(0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                       tokens_stemm  label  \\\n",
       "0  216356   [im, feel, virtuou, avoid, chip, aisl, altogeth]      1   \n",
       "1   69696  [im, quit, certain, im, tough, time, battl, th...      3   \n",
       "2  196326  [wasnt, feel, quit, thi, appreci, howev, shove...      1   \n",
       "3  207657                                    [feel, disgust]      3   \n",
       "4   31333                                 [feel, fuck, dumb]      0   \n",
       "\n",
       "                                              padded  \n",
       "0  [tensor(4), tensor(2), tensor(699), tensor(849...  \n",
       "1  [tensor(4), tensor(74), tensor(600), tensor(4)...  \n",
       "2  [tensor(249), tensor(2), tensor(74), tensor(6)...  \n",
       "3  [tensor(2), tensor(376), tensor(0), tensor(0),...  \n",
       "4  [tensor(2), tensor(226), tensor(528), tensor(0...  "
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['padded'] = train_data['tokens_stemm'].apply(pad_sequence)\n",
    "val_data['padded'] = val_data['tokens_stemm'].apply(pad_sequence)\n",
    "test_data['padded'] = test_data['tokens_stemm'].apply(pad_sequence)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe[[\"padded\",\"label\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        output = self.dataframe.iloc[index]\n",
    "        return {\n",
    "            \"padded\": output['padded'],\n",
    "            \"label\": output['label']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = PandasDataset(train_data)\n",
    "X_val_dataset = PandasDataset(val_data)\n",
    "X_test_dataset = PandasDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batched = DataLoader(X_train_dataset, batch_size= 256)\n",
    "X_val_batched = DataLoader(X_val_dataset, batch_size= 64)\n",
    "X_test_batched = DataLoader(X_test_dataset, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "        \n",
    "class CNNTextClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size:int = 52000, \n",
    "                 embedding_dim:int = 16, \n",
    "                 input_length:int = 100, \n",
    "                 num_filters:int = 128, \n",
    "                 kernel_size:int = 5, \n",
    "                 hidden_units:int = 64, \n",
    "                 num_classes:int = 6):\n",
    "        super(CNNTextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1d = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=input_length - kernel_size + 1)\n",
    "        self.fc1 = nn.Linear(num_filters, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  # Change shape for Conv1D\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze(2)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size:int = 128,\n",
    "                hidden_size:int = 64,\n",
    "                num_layers:int = 1,\n",
    "                output_size:int = 6,\n",
    "                dropout:float = 0.1\n",
    "                ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=52000, embedding_dim= input_size)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size = input_size,\n",
    "                              hidden_size = hidden_size,\n",
    "                              num_layers = num_layers,\n",
    "                              bidirectional=True)\n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Dropout(p=dropout),\n",
    "                                   nn.Linear(hidden_size*2, 128),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(128, output_size),\n",
    "                                   nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x: torch.TensorType):\n",
    "        emb = self.embedding(x)\n",
    "        \n",
    "        # bilstm\n",
    "        for i in range(emb.size(-2)):\n",
    "            if i == 0:\n",
    "                lstm_out, (hidden,cell) = self.bilstm(emb[:,i,:])\n",
    "            else:\n",
    "                lstm_out, (hidden,cell) = self.bilstm(emb[:,i,:], (hidden,cell))\n",
    "\n",
    "        # Fully connected layers\n",
    "        out = self.dense(lstm_out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, num_epochs, learning_rate):\n",
    "    # import math\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    start_lr = learning_rate * 100\n",
    "    end_lr = learning_rate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
    "    \n",
    "    # lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / num_epochs * len(train_dataloader))\n",
    "    # scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    epoch_loss, epoch_acc = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_correct_predictions = 0\n",
    "        train_total_predictions = 0\n",
    "        \n",
    "        for batch in tqdm(train_dataloader):\n",
    "            inputs = batch['padded'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            # print(inputs.size())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            \n",
    "            train_running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct_predictions += (predicted == labels).sum().item()\n",
    "            train_total_predictions += labels.size(0)\n",
    "        \n",
    "        train_epoch_loss = train_running_loss / len(train_dataloader.dataset)\n",
    "        train_epoch_accuracy = train_correct_predictions / train_total_predictions\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                val_inputs = batch['padded'].to(device)\n",
    "                val_labels = batch['label'].to(device)\n",
    "                \n",
    "                val_outputs = model(val_inputs)\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "                val_total_predictions += val_labels.size(0)\n",
    "        \n",
    "        val_epoch_accuracy = val_correct_predictions / val_total_predictions\n",
    "        \n",
    "        epoch_loss.append(train_epoch_loss)\n",
    "        epoch_acc.append(val_epoch_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_epoch_loss:.4f}, Train Accuracy: {train_epoch_accuracy:.4f}, '\n",
    "              f'Val Accuracy: {val_epoch_accuracy:.4f}')\n",
    "        \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNTextClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:28<00:00,  7.65it/s]\n",
      "  0%|          | 1/1138 [00:00<02:40,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 1.5205, Train Accuracy: 0.5183, Val Accuracy: 0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:34<00:00,  7.36it/s]\n",
      "  0%|          | 1/1138 [00:00<03:15,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Train Loss: 1.2890, Train Accuracy: 0.7552, Val Accuracy: 0.8111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:32<00:00,  7.46it/s]\n",
      "  0%|          | 1/1138 [00:00<02:28,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Train Loss: 1.1993, Train Accuracy: 0.8450, Val Accuracy: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:38<00:00,  7.18it/s]\n",
      "  0%|          | 1/1138 [00:00<02:23,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Train Loss: 1.1701, Train Accuracy: 0.8731, Val Accuracy: 0.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:35<00:00,  7.32it/s]\n",
      "  0%|          | 1/1138 [00:00<02:42,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Train Loss: 1.1596, Train Accuracy: 0.8838, Val Accuracy: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:49<00:00,  6.72it/s]\n",
      "  0%|          | 1/1138 [00:00<03:04,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Train Loss: 1.1540, Train Accuracy: 0.8894, Val Accuracy: 0.8792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:53<00:00,  6.54it/s]\n",
      "  0%|          | 0/1138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Train Loss: 1.1508, Train Accuracy: 0.8926, Val Accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:41<00:00,  7.04it/s]\n",
      "  0%|          | 1/1138 [00:00<02:32,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Train Loss: 1.1466, Train Accuracy: 0.8968, Val Accuracy: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:38<00:00,  7.17it/s]\n",
      "  0%|          | 0/1138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Train Loss: 1.1359, Train Accuracy: 0.9079, Val Accuracy: 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:42<00:00,  7.00it/s]\n",
      "  0%|          | 0/1138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Train Loss: 1.1318, Train Accuracy: 0.9118, Val Accuracy: 0.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:39<00:00,  7.14it/s]\n",
      "  0%|          | 1/1138 [00:00<03:04,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Train Loss: 1.1291, Train Accuracy: 0.9144, Val Accuracy: 0.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:46<00:00,  6.84it/s]\n",
      "  0%|          | 1/1138 [00:00<02:24,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Train Loss: 1.1265, Train Accuracy: 0.9168, Val Accuracy: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:50<00:00,  6.67it/s]\n",
      "  0%|          | 1/1138 [00:00<02:41,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Train Loss: 1.1246, Train Accuracy: 0.9188, Val Accuracy: 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:41<00:00,  7.07it/s]\n",
      "  0%|          | 1/1138 [00:00<02:43,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Train Loss: 1.1239, Train Accuracy: 0.9194, Val Accuracy: 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:39<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Train Loss: 1.1226, Train Accuracy: 0.9208, Val Accuracy: 0.9016\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = train(model, X_train_batched, X_val_batched, 15, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, y_true, num_classes):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix for label encodings in PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    y_pred (torch.Tensor): Predicted labels tensor.\n",
    "    y_true (torch.Tensor): True labels tensor.\n",
    "    num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Confusion matrix.\n",
    "    \"\"\" \n",
    "    # if len(y_pred) != len(y_true):\n",
    "    #     raise ValueError(\"Shapes of predictions and true labels must match. y_pred shape: {} y_true shape: {}\".format(y_pred.shape, y_true.shape))\n",
    "\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "\n",
    "    y_pred_np = y_pred.argmax(dim=1).cpu().numpy()\n",
    "    y_true_np = y_true.cpu().numpy()\n",
    "\n",
    "    for pred, true in zip(y_pred_np, y_true_np):\n",
    "        conf_matrix[pred, true] += 1\n",
    "\n",
    "    return conf_matrix\n",
    "\n",
    "def calculate_confusion_matrix(test_emb, test_labels, model):\n",
    "    model.eval()\n",
    "    output = model(test_emb)\n",
    "    return confusion_matrix(output, test_labels, 6)\n",
    "\n",
    "def class_accuracy(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for each class based on a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    conf_matrix (numpy.ndarray): Confusion matrix.\n",
    "\n",
    "    Returns:\n",
    "    list: List of accuracies for each class.\n",
    "    \"\"\"\n",
    "    # diagonal = np.diag(conf_matrix)\n",
    "\n",
    "    # row_sums = conf_matrix.sum(axis=1)\n",
    "\n",
    "    # accuracies = diagonal / row_sums.astype(float)\n",
    "\n",
    "    # return accuracies\n",
    "    \n",
    "    diagonal = np.diag(conf_matrix)\n",
    "    row_sums = conf_matrix.sum(axis=1)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        accuracies = np.where(row_sums != 0, diagonal / row_sums.astype(float), 0.0)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "def class_f1_score(conf_matrix, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Calculate F1 score for each class based on a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    conf_matrix (numpy.ndarray): Confusion matrix.\n",
    "    epsilon (float): Smoothing term to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    list: List of F1 scores for each class.\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = np.diag(conf_matrix)\n",
    "    fp = conf_matrix.sum(axis=0) - tp\n",
    "    fn = conf_matrix.sum(axis=1) - tp\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1301 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1301/1301 [00:34<00:00, 37.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.9238047  0.90075722 0.87041241 0.91210746 0.91165872 0.74483028] \n",
      " Average acccuracy: 87.73%\n",
      "F1 Scores: [0.94925082 0.92756218 0.75259666 0.90526218 0.86510033 0.6970969 ] \n",
      " Average F1: 84.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cm = None\n",
    "for batch in tqdm(X_test_batched):\n",
    "    inputs = batch['padded']\n",
    "    labels = batch['label']\n",
    "    cm_helper = calculate_confusion_matrix(inputs, labels, model)\n",
    "    if cm is None:\n",
    "        cm = cm_helper\n",
    "    else:\n",
    "        cm = np.add(cm, cm_helper)\n",
    "    \n",
    "accuracies = class_accuracy(cm)\n",
    "f1_scores = class_f1_score(cm)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "print(f\"Accuracies: {accuracies} \\n Average acccuracy: {average_accuracy*100:.2f}%\")\n",
    "print(f\"F1 Scores: {f1_scores} \\n Average F1: {average_f1*100:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    labels = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"}\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(conf_matrix, cmap='coolwarm', interpolation='nearest', vmax=3000)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.xticks(list(labels.keys()), [labels[i] for i in range(len(labels))])\n",
    "    plt.yticks(list(labels.keys()), [labels[i] for i in range(len(labels))])\n",
    "    \n",
    "    plt.xlabel('Predicted label',fontdict={\"fontweight\":\"bold\"})\n",
    "    plt.ylabel('True label',fontdict={\"fontweight\":\"bold\"})\n",
    "    plt.title('Confusion Matrix',fontdict={\"fontsize\":15,\"fontweight\":\"bold\"})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
